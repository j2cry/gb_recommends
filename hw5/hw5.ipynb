{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Q: В чем принципиальное отличие гибридных рекомендательных систем от коллаборативной филтьтрации? Приведите 2-3 примера задач, в которых необходимо использовать гибридные системы.\n",
    "\n",
    "A: Поскольку коллаборативная фильтрация основана на матричной факторизации, она учитывает только реальные user-item взаимодействия (купил/не купил), игнорируя остальные доступные параметры (бренды товаров, время совершения покупки, частота покупок, возраст пользователей, их социальный статус, etc). В связи с этим возникает проблема \"холодного старта\": выдачи рекомендаций новым или мало активным пользователям, а также рекомендация новых товаров. И в предыдущих работах этого курса можно заметить, что некоторые алгоритмы выдают меньше предсказаний, чем необходимо. Гибридная рекомендательная система решает эти проблемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Q: Прочитайте статью про поиск на hh.ru https://habr.com/ru/company/hh/blog/347276/ Нам интересна именно рекомендательная система, раздел “Производительность системы” можно пропустить Какие основные отличия предложенной системы от тех подходов, которые мы разбирали на семинарах? Какие проблемы могут возникнуть при выводе такой модели в продакшен?\n",
    "\n",
    "A: Описанная рекомендательная система HH состоит (в общем виде) из 4-х элементов (см. рис. Схема работы рекомендательной системы). На вебинарах мы рассматривали состоящие только из 2-х (ALS similar-user + item-item). К сожалению, в статье нет подробного описания работы каждого этапа моделирования, но в качестве примера сложностей в продакшене предположу следующее: эвристический фильтр на 2-х признаках и фльтрующая модель 1 - на 4-х - работают, скорее всего быстро, но насколько качественно - вопрос. Также не очень понятно, как решается проблема индексации и генерации признаков для неполных или некорректно заполненных вакансий/резюме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Q: На вебинаре мы рассматривали модель LightFM (https://making.lyst.com/lightfm/docs/lightfm.html). В работе Data Scientist’а важную часть занимает research - исследование существующих архитектур и разбор научных статей, в которых они описываются. Вам предлагается изчуть оригинальную статью про LightFM https://arxiv.org/pdf/1507.08439.pdf и ответить на следующие вопросы:\n",
    "1) Какой датасет используют авторы?\n",
    "2) Что используют в качестве признаков?\n",
    "3) С какими моделями сравнивают LightFM? Опишите их основные идеи кратко"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "from additional import DataProcessor\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load purchases\n",
    "purchases = pd.read_csv('retail_train.csv')\n",
    "\n",
    "# train/test split\n",
    "test_size_weeks = 3\n",
    "train = purchases[purchases['week_no'] < purchases['week_no'].max() - test_size_weeks].copy()\n",
    "test = purchases[purchases['week_no'] >= purchases['week_no'].max() - test_size_weeks].copy()\n",
    "\n",
    "# prepare true values\n",
    "# true_values = test.groupby('user_id')['item_id'].unique().reset_index()\n",
    "# true_values.columns=['user_id', 'actual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA в отдельном блокноте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "подготовим параметры обработки датасета:\n",
    "* defaults: на основе кол-ва проданных товаров\n",
    "* mix_feat: на комбинации стоимости и кол-ва проданных товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mix_feat_params = {\n",
    "    'top_config': {'fields': ['quantity', 'sales_value'],\n",
    "                   'beta': [1., 1.],\n",
    "                   'k': 5000,\n",
    "                   'scaler': StandardScaler},\n",
    "    'uim_config': {'aggfunc': 'sum',\n",
    "                #    'weights': bm25_weight\n",
    "                   },\n",
    "}\n",
    "\n",
    "defaults_params = {\n",
    "    'top_config': {'fields': ['quantity'],\n",
    "                   'k': 5000},\n",
    "    'uim_config': {'aggfunc': 'sum',\n",
    "                #    'weights': bm25_weight\n",
    "                   },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# создаем хранилище обучающих и валидационных данных\n",
    "preparer = DataProcessor(train, test, **mix_feat_params)\n",
    "preparer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Item featuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "# load items data\n",
    "item_data = pd.read_csv('product.csv')\n",
    "item_data.columns = item_data.columns.str.lower()\n",
    "item_data.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "# dummy\n",
    "item_features = pd.DataFrame(preparer.train_uim.columns)\n",
    "item_features = item_features.merge(item_data, on='item_id', how='left')\n",
    "item_features.set_index('item_id', inplace=True)\n",
    "item_features = pd.get_dummies(item_features, columns=item_features.columns.tolist())\n",
    "del item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## User featuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline user/item features\n",
    "# load users data\n",
    "user_data = pd.read_csv('hh_demographic.csv')\n",
    "user_data.columns = user_data.columns.str.lower()\n",
    "user_data.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# dummy\n",
    "user_features = pd.DataFrame(preparer.train_uim.index)\n",
    "user_features = user_features.merge(user_data, on='user_id', how='left')\n",
    "user_features.set_index('user_id', inplace=True)\n",
    "user_features = pd.get_dummies(user_features, columns=user_features.columns.tolist())\n",
    "del user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Загружаем user features, их подготовка - в одноименном блокноте\n",
    "user_data = pd.read_csv('user_features_corrected.csv')\n",
    "user_features = pd.DataFrame(preparer.train_uim.index)\n",
    "user_features = user_features.merge(user_data, on='user_id', how='left').fillna(0)\n",
    "user_features.set_index('user_id', inplace=True)\n",
    "del user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fcc34dc5130>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=10,\n",
    "                loss='warp', # 'bpr'\n",
    "                learning_rate=0.2,\n",
    "                item_alpha=0.1, # смещение по товару\n",
    "                user_alpha=0.1,\n",
    "                random_state=42)\n",
    "\n",
    "model.fit((preparer.train_uim_sparse > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(preparer.train_uim),\n",
    "          user_features=csr_matrix(user_features.values).tocsr(),\n",
    "          item_features=csr_matrix(item_features.values).tocsr(),\n",
    "          epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pr@5: 0.3733547329902649\n",
      "Test pr@5: 0.003846153849735856\n"
     ]
    }
   ],
   "source": [
    "train_pr = precision_at_k(model, preparer.train_uim_sparse, k=5,\n",
    "                          user_features=csr_matrix(user_features.values),\n",
    "                          item_features=csr_matrix(item_features.values)).mean()\n",
    "\n",
    "test_pr = precision_at_k(model, preparer.test_uim_sparse, k=5,\n",
    "                         user_features=csr_matrix(user_features.values).tocsr(),\n",
    "                         item_features=csr_matrix(item_features.values).tocsr()).mean()\n",
    "\n",
    "print(f'Train pr@5: {train_pr}', f'Test pr@5: {test_pr}', sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# item_index = np.arange(preparer.train_uim.columns.size)\n",
    "# predictions = model.predict(user_ids=6, item_ids=item_index,\n",
    "#                             user_features=csr_matrix(user_features.values).tocsr(),\n",
    "#                             item_features=csr_matrix(item_features.values).tocsr(),\n",
    "#                             num_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline: 0.4366 / 0.0026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
