{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "from additional import DataProcessor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from hyperopt import hp, fmin, tpe\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## load & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load purchases\n",
    "purchases = pd.read_csv('retail_train.csv')\n",
    "\n",
    "# train/test split\n",
    "test_size_weeks = 3\n",
    "train = purchases[purchases['week_no'] < purchases['week_no'].max() - test_size_weeks].copy()\n",
    "test = purchases[purchases['week_no'] >= purchases['week_no'].max() - test_size_weeks].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA в отдельном блокноте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "подготовим параметры обработки датасета:\n",
    "* defaults: на основе кол-ва проданных товаров\n",
    "* mix_feat: на комбинации стоимости и кол-ва проданных товаров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mix_feat_params = {\n",
    "    'top_config': {'fields': ['quantity', 'sales_value'],\n",
    "                   'beta': [1., 1.],\n",
    "                   'k': 5000,\n",
    "                   'scaler': StandardScaler},\n",
    "    'uim_config': {'aggfunc': 'sum',\n",
    "                #    'weights': bm25_weight\n",
    "                   },\n",
    "}\n",
    "\n",
    "defaults_params = {\n",
    "    'top_config': {'fields': ['quantity'],\n",
    "                   'k': 5000},\n",
    "    'uim_config': {'aggfunc': 'count',\n",
    "    #             #    'weights': bm25_weight\n",
    "                   },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# создаем хранилище обучающих и валидационных данных\n",
    "preparer = DataProcessor(train, test, **mix_feat_params)\n",
    "preparer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Item featuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load items data\n",
    "item_data = pd.read_csv('product.csv')\n",
    "item_data.columns = item_data.columns.str.lower()\n",
    "item_data.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "\n",
    "# drop columns\n",
    "# много информации - тоже плохо\n",
    "# уберем инфу о весе - она интуитивно неинформативна и commodity_desc как промежуточную категорию - в датасете есть department и sub_commodity_desc\n",
    "# keep_cols = ['item_id', 'manufacturer', 'sub_commodity_desc', 'department', 'brand']\n",
    "keep_cols = ['item_id', 'manufacturer', 'sub_commodity_desc']\n",
    "item_data = item_data[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # day rate\n",
    "# day_rate = (purchases.groupby('item_id')['day'].nunique() / purchases['day'].max()).rename('day_rate')\n",
    "# everyday = day_rate > 0.71                      # ~соотв. 5 дней из 7\n",
    "# everyweek = ~everyday & (day_rate > 0.42)       # ~соотв. 3 дням из 7\n",
    "# day_rate[everyday] = 'everyday'\n",
    "# day_rate[everyweek] = 'everyweek'\n",
    "# day_rate[~everyday & ~everyweek] = 'episodic'\n",
    "# item_data = item_data.merge(day_rate, on='item_id', how='left').fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy\n",
    "item_features = pd.DataFrame(preparer.train_uim.columns)\n",
    "item_features = item_features.merge(item_data, on='item_id', how='left')\n",
    "item_features.set_index('item_id', inplace=True)\n",
    "item_features = pd.get_dummies(item_features, columns=item_features.columns.tolist())\n",
    "del item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## User featuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем user data, их подготовка - в одноименном блокноте\n",
    "user_data = pd.read_csv('user_features_corrected.csv')\n",
    "user_features = pd.DataFrame(preparer.train_uim.index)\n",
    "user_features = user_features.merge(user_data, on='user_id', how='left').fillna(0)\n",
    "user_features.set_index('user_id', inplace=True)\n",
    "\n",
    "# get features' columns\n",
    "# age = user_data.columns[user_data.columns.str.match('age')].to_list()\n",
    "# marital = user_data.columns[user_data.columns.str.match('marital')].to_list()\n",
    "income = user_data.columns[user_data.columns.str.match('income')].to_list()\n",
    "# homeowner = user_data.columns[user_data.columns.str.match('homeowner')].to_list()\n",
    "# single = user_data.columns[user_data.columns.str.match('single')].to_list()\n",
    "# size = user_data.columns[user_data.columns.str.match('hh_size')].to_list()\n",
    "# kids = user_data.columns[user_data.columns.str.match('kids')].to_list()\n",
    "\n",
    "# drop/reorder features\n",
    "# user_features.drop(columns=[*homeowner], inplace=True)\n",
    "# user_features = user_features[[*income, *marital, *size, *single, *kids]]\n",
    "# user_features = user_features[[*homeowner,]]\n",
    "\n",
    "# user_features = user_features[[*income, *kids, *size, *age, *marital]]\n",
    "user_features = user_features[[*income]]\n",
    "del user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test для проверки без фичей - модель работает как матричная факторизация\n",
    "# add_cols = [col for col in preparer.train_uim.columns if col not in preparer.test_uim.columns]\n",
    "# tst = pd.concat([preparer.test_uim, pd.DataFrame(columns=add_cols)], axis=1)[preparer.train_uim.columns]\n",
    "# add_index = [row for row in preparer.train_uim.index if row not in preparer.test_uim.index]\n",
    "# tst = pd.concat([tst, pd.DataFrame(add_index)])\n",
    "# tst.fillna(0, inplace=True)\n",
    "# tst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pr@5: 0.03731942176818848\n",
      "Test pr@5: 0.043522268533706665\n"
     ]
    }
   ],
   "source": [
    "# model_params = {      # baseline params\n",
    "#     'no_components': 10,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'item_alpha': 0.1,\n",
    "#     'user_alpha': 0.1,\n",
    "# }\n",
    "model_params = {k: int(v) if k == 'no_components' else v for k, v in json.load(open('hypopt.json'))['params'].items()}\n",
    "\n",
    "model = LightFM(loss='warp', # 'bpr'\n",
    "                random_state=42,\n",
    "                **model_params)\n",
    "\n",
    "model.fit((preparer.train_uim_sparse > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(preparer.train_uim_weighted),\n",
    "          user_features=csr_matrix(user_features.values).tocsr(),\n",
    "          item_features=csr_matrix(item_features.values).tocsr(),\n",
    "          epochs=10)\n",
    "\n",
    "train_pr = precision_at_k(model, preparer.train_uim_weighted, k=5,\n",
    "                          user_features=csr_matrix(user_features.values),\n",
    "                          item_features=csr_matrix(item_features.values)\n",
    "                          ).mean()\n",
    "\n",
    "# test_pr = precision_at_k(model, csr_matrix(tst).tocsr(), k=5,\n",
    "test_pr = precision_at_k(model, preparer.test_uim_weighted, k=5,\n",
    "                         user_features=csr_matrix(user_features.values).tocsr(),\n",
    "                         item_features=csr_matrix(item_features.values).tocsr()\n",
    "                         ).mean()\n",
    "\n",
    "print(f'Train pr@5: {train_pr}', f'Test pr@5: {test_pr}', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# item_index = np.arange(preparer.train_uim.columns.size)\n",
    "# predictions = model.predict(user_ids=6, item_ids=item_index,\n",
    "#                             user_features=csr_matrix(user_features.values).tocsr(),\n",
    "#                             item_features=csr_matrix(item_features.values).tocsr(),\n",
    "#                             num_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopt_history = [{},]\n",
    "hopt_metrics = [0,]\n",
    "\n",
    "# define objective function\n",
    "def objective(params):\n",
    "    model = LightFM(**params, loss='warp', random_state=42)\n",
    "\n",
    "    model.fit((preparer.train_uim_sparse > 0) * 1,  # user-item matrix из 0 и 1\n",
    "            sample_weight=coo_matrix(preparer.train_uim_weighted),\n",
    "            user_features=csr_matrix(user_features.values).tocsr(),\n",
    "            item_features=csr_matrix(item_features.values).tocsr(),\n",
    "            epochs=10)\n",
    "\n",
    "    _pr = precision_at_k(model, preparer.test_uim_sparse, k=5,\n",
    "                         user_features=csr_matrix(user_features.values).tocsr(),\n",
    "                         item_features=csr_matrix(item_features.values).tocsr()).mean()\n",
    "    hopt_history.append(params)\n",
    "    hopt_metrics.append(_pr)    \n",
    "    return 1 / _pr if _pr else np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a search space\n",
    "search_space = {'no_components': 5 + hp.randint('no_components', 95),\n",
    "                'learning_rate': hp.uniform('learning_rate', 1e-5, 0.4),\n",
    "                'item_alpha': hp.uniform('item_alpha', 0, 0.4),\n",
    "                'user_alpha': hp.uniform('user_alpha', 0, 0.4),\n",
    "                }\n",
    "\n",
    "static_params = {'loss': 'warp',\n",
    "                 'random_state': 42,\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # manual searching\n",
    "# best = fmin(objective, search_space, algo=tpe.suggest, max_evals=5)\n",
    "# best.update(static_params)\n",
    "# hopt_history[np.array(hopt_metrics).argmax()], max(hopt_metrics)\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # manual save\n",
    "# saved_best = json.load(open('hypopt.json'))\n",
    "# params, metric = hopt_history[np.array(hopt_metrics).argmax()], max(hopt_metrics)\n",
    "# if metric > saved_best['metric']:\n",
    "#     saved_best = {'metric': float(metric), 'params': {k: float(v) for k, v in params.items()}}\n",
    "#     json.dump(saved_best, open('hypopt.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:28<00:00, 17.78s/trial, best loss: 83.02520590987774] \n",
      "100%|██████████| 5/5 [01:35<00:00, 19.01s/trial, best loss: 161.96720476642002]\n",
      "100%|██████████| 5/5 [01:22<00:00, 16.57s/trial, best loss: 22.976743485361535]\n",
      "100%|██████████| 5/5 [01:10<00:00, 14.04s/trial, best loss: 103.999986052515]  \n",
      "100%|██████████| 5/5 [00:58<00:00, 11.76s/trial, best loss: 164.6666625260066] \n",
      "100%|██████████| 5/5 [01:53<00:00, 22.76s/trial, best loss: 111.01123230281387]\n",
      "100%|██████████| 5/5 [01:26<00:00, 17.34s/trial, best loss: 141.14285823201038]\n",
      "100%|██████████| 5/5 [01:14<00:00, 14.86s/trial, best loss: 125.06328326027291]\n",
      "100%|██████████| 5/5 [01:15<00:00, 15.16s/trial, best loss: 87.43363128173183]\n",
      "100%|██████████| 5/5 [01:57<00:00, 23.46s/trial, best loss: 129.9999920092528] \n",
      "100%|██████████| 5/5 [01:00<00:00, 12.12s/trial, best loss: 135.34246618854752]\n",
      "100%|██████████| 5/5 [01:59<00:00, 23.89s/trial, best loss: 120.48781063649244]\n",
      "100%|██████████| 5/5 [01:26<00:00, 17.28s/trial, best loss: 117.61904852667533]\n",
      "100%|██████████| 5/5 [01:51<00:00, 22.35s/trial, best loss: 73.73134421418268]\n",
      "100%|██████████| 5/5 [01:08<00:00, 13.62s/trial, best loss: 63.33333435571858]\n",
      "100%|██████████| 5/5 [02:13<00:00, 26.77s/trial, best loss: 141.14285823201038]\n",
      "100%|██████████| 5/5 [01:26<00:00, 17.22s/trial, best loss: 36.728625402042546]\n",
      "100%|██████████| 5/5 [01:26<00:00, 17.38s/trial, best loss: 83.02521232965687] \n",
      "100%|██████████| 5/5 [01:56<00:00, 23.37s/trial, best loss: 159.35483825008282]\n",
      "100%|██████████| 5/5 [01:37<00:00, 19.55s/trial, best loss: 129.9999920092528] \n",
      "CPU times: user 30min 30s, sys: 660 ms, total: 30min 31s\n",
      "Wall time: 30min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 0.043522268533706665,\n",
       " 'params': {'item_alpha': 0.3715697055298993,\n",
       "  'learning_rate': 0.21255221183657733,\n",
       "  'no_components': 13.0,\n",
       "  'user_alpha': 0.2145757171965058}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# # поиск в несколько подходов\n",
    "# n_cycles = 20\n",
    "# best_arr = []       # набор параметров, которые алгоритм счел лучшими\n",
    "\n",
    "# saved_best = json.load(open('hypopt.json'))\n",
    "# for _ in range(n_cycles):\n",
    "#     try:\n",
    "#         best = fmin(objective, search_space, algo=tpe.suggest, max_evals=5)\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "#     else:\n",
    "#         best.update(static_params)\n",
    "#         best_arr.append(best)\n",
    "\n",
    "#     params, metric = hopt_history[np.array(hopt_metrics).argmax()], max(hopt_metrics)\n",
    "#     if metric > saved_best['metric']:\n",
    "#         saved_best = {'metric': float(metric), 'params': {k: float(v) for k, v in params.items()}}\n",
    "#         json.dump(saved_best, open('hypopt.json', 'w'))\n",
    "\n",
    "# saved_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline: 0.4366 / 0.0026\n",
    "\n",
    "common: 0.390 / 0.00587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}