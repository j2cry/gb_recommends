{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 679,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from datasplit import DataSplit\n",
    "from preprocess import DataPreprocessor\n",
    "from candidate_model import CandidateModel\n",
    "from metrics import precision_at_k, recall_at_k, ap_k, calc_mean_metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## prepare data & fit candidate model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "outputs": [],
   "source": [
    "purchases = pd.read_csv('retail_train.csv')\n",
    "\n",
    "# train/valid split\n",
    "splitter = DataSplit(purchases, 'week_no', [6, 4])\n",
    "\n",
    "train_lv1 = purchases[splitter.part0].copy()\n",
    "valid_lv1 = purchases[splitter.part1].copy()\n",
    "valid_lv2 = purchases[splitter.part2].copy()\n",
    "\n",
    "# prepare lv1 validation true values\n",
    "true_train_lv1 = train_lv1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "true_train_lv1.columns=['user_id', 'actual']\n",
    "true_valid_lv1 = valid_lv1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "true_valid_lv1.columns=['user_id', 'actual']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "outputs": [],
   "source": [
    "mix_feat_params = {\n",
    "    'top_config': {'fields': ['quantity', 'sales_value'],\n",
    "                   'beta': [1., 1.],\n",
    "                   'k': 5000,\n",
    "                   'scaler': StandardScaler\n",
    "                    },\n",
    "    'uim_config': {'aggfunc': 'sum',\n",
    "                   # 'weights': tfidf_weight\n",
    "                   },\n",
    "}\n",
    "\n",
    "pre = DataPreprocessor(train_lv1, valid_lv1, **mix_feat_params)\n",
    "pre.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.24309811427640554, 0.18430627660815352)"
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_params = {\n",
    "    'train': pre.train_uim_sparse,\n",
    "    'weighted': pre.train_uim_weighted,\n",
    "    'top_items': pre.top_k_items,\n",
    "    'placeholder_id': pre.placeholder_id,\n",
    "    'idx_to_item': pre.idx_to_item,\n",
    "    'item_to_idx': pre.item_to_idx,\n",
    "    'user_to_idx': pre.user_to_idx\n",
    "}\n",
    "n_candidates = 70\n",
    "cm = CandidateModel('BM25', **candidate_params)\n",
    "cm.fit(K=1)\n",
    "train_candidates = cm.predict(true_train_lv1['user_id'], N=n_candidates)\n",
    "valid_candidates = cm.predict(true_valid_lv1['user_id'], N=n_candidates)\n",
    "\n",
    "recall_lv1_train = calc_mean_metric(recall_at_k, true_train_lv1['actual'], train_candidates, k=n_candidates)\n",
    "recall_lv1_valid = calc_mean_metric(recall_at_k, true_valid_lv1['actual'], valid_candidates, k=n_candidates)\n",
    "recall_lv1_train, recall_lv1_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "outputs": [
    {
     "data": {
      "text/plain": "(150780, 2)"
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unstack candidates\n",
    "candidates = pd.DataFrame.from_dict(valid_candidates.to_dict(), orient='index').set_index(true_valid_lv1['user_id'])\n",
    "candidates = candidates.stack().reset_index(level=1, drop=True).rename('item_id').reset_index()\n",
    "candidates.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## prepare data for lv2 model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "outputs": [
    {
     "data": {
      "text/plain": "(164810, 2)"
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leave only warm users in dataset\n",
    "train_users = train_lv1['user_id'].unique()\n",
    "warm_users = valid_lv1['user_id'].isin(train_users)\n",
    "train_target_lv2 = valid_lv1.loc[warm_users, ['user_id', 'item_id']].copy()\n",
    "# train_target_lv2 = valid_lv1.copy()       # or both warm & cold\n",
    "\n",
    "# markup candidates and merge with real items\n",
    "train_target_lv2['target'] = 1      # flag means this item was really bought\n",
    "train_data_lv2 = candidates.merge(train_target_lv2, on=['user_id', 'item_id'], how='left').fillna(0)\n",
    "train_lv2_empty = train_data_lv2.drop(columns='target')\n",
    "train_lv2_empty.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "outputs": [
    {
     "data": {
      "text/plain": "(157666, 2)"
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same for validation data\n",
    "valid_target_lv2 = valid_lv2[['user_id', 'item_id']].copy()\n",
    "valid_target_lv2['target'] = 1\n",
    "valid_data_lv2 = candidates.merge(valid_target_lv2, on=['user_id', 'item_id'], how='left').fillna(0)\n",
    "valid_lv2_empty = valid_data_lv2.drop(columns='target')\n",
    "valid_lv2_empty.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "outputs": [
    {
     "data": {
      "text/plain": "0.21866998361749893"
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля релевантных товаров среди кандидатов\n",
    "zeros, ones = train_data_lv2['target'].value_counts()\n",
    "ones / (ones + zeros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### feature engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "outputs": [],
   "source": [
    "# baseline item features\n",
    "cat_items = []\n",
    "item_data = pd.read_csv('product.csv')\n",
    "item_data.columns = item_data.columns.str.lower()\n",
    "item_data.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "# item_data.drop(columns=['curr_size_of_product'], inplace=True)\n",
    "keep_cols = ['item_id', 'department',]\n",
    "item_data = item_data[keep_cols]\n",
    "\n",
    "# baseline user features\n",
    "user_data = pd.read_csv('../hw5/user_features_corrected.csv')\n",
    "\n",
    "# merge dummies\n",
    "train_lv2 = train_lv2_empty.copy()\n",
    "train_lv2 = train_lv2.merge(pd.get_dummies(item_data), on='item_id', how='left').fillna(0)\n",
    "train_lv2 = train_lv2.merge(user_data, on='user_id', how='left').fillna(0)\n",
    "\n",
    "valid_lv2 = valid_lv2_empty.copy()\n",
    "valid_lv2 = valid_lv2.merge(pd.get_dummies(item_data), on='item_id', how='left').fillna(0)\n",
    "valid_lv2 = valid_lv2.merge(user_data, on='user_id', how='left').fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "outputs": [],
   "source": [
    "# add some features\n",
    "# ...\n",
    "# make pipeline for valid lv2 preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "outputs": [],
   "source": [
    "# # load items data\n",
    "# item_data = pd.read_csv('product.csv')\n",
    "# item_data.columns = item_data.columns.str.lower()\n",
    "# item_data.rename(columns={'product_id': 'item_id'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "outputs": [],
   "source": [
    "# # day rate: % дней в которые товар был продан\n",
    "# day_rate = (purchases.groupby('item_id')['day'].nunique() / purchases['day'].max()).rename('day_rate')\n",
    "# item_data = item_data.merge(day_rate, on='item_id', how='left').fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "outputs": [],
   "source": [
    "# # basket rate: % уникальных чеков в которых присутствовал товар\n",
    "# basket_rate = (purchases.groupby('item_id')['basket_id'].nunique() / purchases['basket_id'].nunique()).rename('basket_rate')\n",
    "# item_data = item_data.merge(basket_rate, on='item_id', how='left').fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "outputs": [],
   "source": [
    "# # load users data\n",
    "# user_data = pd.read_csv('hh_demographic.csv')\n",
    "# user_data.columns = user_data.columns.str.lower()\n",
    "# user_data.rename(columns={'household_key': 'user_id'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "outputs": [],
   "source": [
    "# # featuring train dataset\n",
    "# train_lv2 = train_lv2_empty.copy()\n",
    "\n",
    "# train_lv2 = train_lv2.merge(day_rate, on='item_id', how='left').fillna(0)\n",
    "# train_lv2 = train_lv2.merge(basket_rate, on='item_id', how='left').fillna(0)\n",
    "# train_lv2 = train_lv2.merge(item_data, on='user_id', how='left').fillna(0)\n",
    "\n",
    "# train_lv2 = train_lv2.merge(user_data, on='user_id', how='left').fillna(0)\n",
    "\n",
    "# categorical_feats = []\n",
    "# train_lv2[categorical_feats] = train_lv2[categorical_feats].astype('category')\n",
    "# train_lv2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  item_id  department_   department_AUTOMOTIVE  \\\n0        1  1082185             0                      0   \n1        1  1082185             0                      0   \n\n   department_CHARITABLE CONT  department_CHEF SHOPPE  \\\n0                           0                       0   \n1                           0                       0   \n\n   department_CNTRL/STORE SUP  department_COSMETICS  \\\n0                           0                     0   \n1                           0                     0   \n\n   department_COUP/STR & MFG  department_DAIRY DELI  ...  income_15-24K  \\\n0                          0                      0  ...            0.0   \n1                          0                      0  ...            0.0   \n\n   income_150-174K  income_175-199K  income_200-249K  income_25-34K  \\\n0              0.0              0.0              0.0            0.0   \n1              0.0              0.0              0.0            0.0   \n\n   income_250K+  income_35-49K  income_50-74K  income_75-99K  income_Under 15K  \n0           0.0            1.0            0.0            0.0               0.0  \n1           0.0            1.0            0.0            0.0               0.0  \n\n[2 rows x 72 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>department_</th>\n      <th>department_AUTOMOTIVE</th>\n      <th>department_CHARITABLE CONT</th>\n      <th>department_CHEF SHOPPE</th>\n      <th>department_CNTRL/STORE SUP</th>\n      <th>department_COSMETICS</th>\n      <th>department_COUP/STR &amp; MFG</th>\n      <th>department_DAIRY DELI</th>\n      <th>...</th>\n      <th>income_15-24K</th>\n      <th>income_150-174K</th>\n      <th>income_175-199K</th>\n      <th>income_200-249K</th>\n      <th>income_25-34K</th>\n      <th>income_250K+</th>\n      <th>income_35-49K</th>\n      <th>income_50-74K</th>\n      <th>income_75-99K</th>\n      <th>income_Under 15K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1082185</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1082185</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 72 columns</p>\n</div>"
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lv2.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "outputs": [
    {
     "data": {
      "text/plain": "((2154, 2), (2154, 2))"
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare lv2 validation true values\n",
    "true_train_lv2 = train_lv2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "true_train_lv2.columns=['user_id', 'actual']\n",
    "true_valid_lv2 = valid_lv2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "true_valid_lv2.columns=['user_id', 'actual']\n",
    "true_train_lv2.shape, true_valid_lv2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fit lv2 LGBM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "outputs": [
    {
     "data": {
      "text/plain": "(Counter({0.0: 163775, 1.0: 1035}),)"
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = LGBMClassifier(objective='binary', max_depth=6, categorical_column=categorical_feats)\n",
    "# model = LGBMClassifier(max_depth=5, learning_rate=0.01, categorical_column=cat_items)\n",
    "model = LGBMClassifier(max_depth=5, learning_rate=0.01,)\n",
    "model.fit(train_lv2, train_data_lv2['target'])\n",
    "\n",
    "train_preds = model.predict(train_lv2)\n",
    "# valid_preds = model.predict(valid_lv2)\n",
    "lgb_pr_train = precision_score(train_data_lv2['target'], train_preds)\n",
    "# lgb_pr_valid = precision_score(data_lv2['target'], valid_preds)\n",
    "\n",
    "Counter(train_preds), # Counter(valid_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "outputs": [],
   "source": [
    "# train proba\n",
    "proba = pd.Series(model.predict_proba(train_lv2).T[1], name='proba')\n",
    "ranked_predicts = pd.concat([train_lv2[['user_id', 'item_id']], proba], axis=1)\n",
    "ranked_candidates = candidates.merge(ranked_predicts, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "# collect recommends\n",
    "k = 5\n",
    "sorted_candidates = ranked_candidates.sort_values(by=['user_id', 'proba'], ascending=[True, False]).groupby('user_id').head(k)\n",
    "\n",
    "# this is for train\n",
    "recommends = sorted_candidates.groupby('user_id')['item_id'].unique()\n",
    "precision_train_lv2 = calc_mean_metric(precision_at_k, true_train_lv2['actual'], recommends.reset_index(drop=True), k=k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "outputs": [],
   "source": [
    "# valid proba\n",
    "proba = pd.Series(model.predict_proba(valid_lv2).T[1], name='proba')\n",
    "ranked_predicts = pd.concat([valid_lv2[['user_id', 'item_id']], proba], axis=1)\n",
    "ranked_candidates = candidates.merge(ranked_predicts, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "# collect recommends\n",
    "k = 5\n",
    "sorted_candidates = ranked_candidates.sort_values(by=['user_id', 'proba'], ascending=[True, False]).groupby('user_id').head(k)\n",
    "\n",
    "# this is for train\n",
    "recommends = sorted_candidates.groupby('user_id')['item_id'].unique()\n",
    "precision_valid_lv2 = calc_mean_metric(precision_at_k, true_valid_lv2['actual'], recommends.reset_index(drop=True), k=k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.82330547818013, 0.8885793871866295)"
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_train_lv2, precision_valid_lv2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fit lv2 XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "outputs": [],
   "source": [
    "# model = XGBClassifier(max_depth=4, subsample=0.5, eta=0.1)\n",
    "# model.fit(train_lv2, data_lv2['target'])\n",
    "#\n",
    "# precision_score(data_lv2['target'], model.predict(train_lv2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "outputs": [],
   "source": [
    "# # train proba\n",
    "# proba = pd.Series(model.predict_proba(train_lv2).T[1], name='proba')\n",
    "# ranked_predicts = pd.concat([train_lv2[['user_id', 'item_id']], proba], axis=1)\n",
    "# ranked_candidates = candidates.merge(ranked_predicts, on=['user_id', 'item_id'], how='left')\n",
    "#\n",
    "# # collect recommends\n",
    "# k = 5\n",
    "# sorted_candidates = ranked_candidates.sort_values(by=['user_id', 'proba'], ascending=[True, False]).groupby('user_id').head(k)\n",
    "#\n",
    "# # this is for train\n",
    "# recommends = sorted_candidates.groupby('user_id')['item_id'].unique()\n",
    "# precision_train_lv2 = calc_mean_metric(precision_at_k, true_train_lv2['actual'], recommends.reset_index(drop=True), k=k)\n",
    "# # precision_valid_lv2 = calc_mean_metric(precision_at_k, true_valid_lv2['actual'], recommends.reset_index(drop=True), k=k)\n",
    "#\n",
    "# precision_train_lv2,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "outputs": [],
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}